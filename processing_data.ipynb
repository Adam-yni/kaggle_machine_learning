{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load GeoJSON file\n",
    "geojson_file = 'train.geojson'\n",
    "gdf = gpd.read_file(geojson_file)\n",
    "\n",
    "\n",
    "# Save DataFrame to XLSX\n",
    "xlsx = 'train.xlsx'\n",
    "gdf.to_excel(xlsx, index=False)\n",
    "\n",
    "# Load GeoJSON file\n",
    "geojson_file = 'test.geojson'\n",
    "gdf = gpd.read_file(geojson_file)\n",
    "\n",
    "\n",
    "# Save DataFrame to XLSX\n",
    "xlsx = 'test.xlsx'\n",
    "gdf.to_excel(xlsx, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# Define the function to process a DataFrame and save to an Excel file\n",
    "def processed_file(df, output_path):\n",
    "    # Clean up the first two columns by removing spaces\n",
    "    df.iloc[:, 0] = df.iloc[:, 0].apply(lambda x: x.replace(' ', '') if isinstance(x, str) else x)\n",
    "    df.iloc[:, 1] = df.iloc[:, 1].apply(lambda x: x.replace(' ', '') if isinstance(x, str) else x)\n",
    "\n",
    "    # Replace missing values with median for specified columns\n",
    "    colonnes_a_traiter = df.columns[2:32]\n",
    "    medianes = df[colonnes_a_traiter].median()\n",
    "    df[colonnes_a_traiter] = df[colonnes_a_traiter].fillna(medianes)\n",
    "\n",
    "    # Process the 'geometry' column to extract polygon coordinates\n",
    "    def processv2(df):\n",
    "        data = df['geometry']\n",
    "        polygons = []\n",
    "\n",
    "        for item in data:\n",
    "            points = []\n",
    "            item = item[10:-2]  # Remove unnecessary characters\n",
    "            segments = item.split(',')\n",
    "\n",
    "            for segment in segments:\n",
    "                a, b = [coord for coord in segment.split(' ') if coord != '']\n",
    "                points.append((float(a), float(b)))\n",
    "\n",
    "            polygons.append(points)\n",
    "\n",
    "        return polygons\n",
    "\n",
    "    # Functions to calculate polygon metrics\n",
    "    def calculate_polygon_area(vertices):\n",
    "        polygon = Polygon(vertices)\n",
    "        return polygon.area\n",
    "    \n",
    "    def calculate_polygon_perimeter(vertices):\n",
    "        polygon = Polygon(vertices)\n",
    "        return polygon.length\n",
    "    \n",
    "    def calculate_height_width_ratio(vertices):\n",
    "        polygon = Polygon(vertices)\n",
    "        bounds = polygon.bounds\n",
    "        height = bounds[3] - bounds[1]\n",
    "        width = bounds[2] - bounds[0]\n",
    "        return height / width\n",
    "    \n",
    "    def calculate_centroid_x(vertices):\n",
    "        polygon = Polygon(vertices)\n",
    "        return polygon.centroid.x\n",
    "    \n",
    "    def calculate_centroid_y(vertices):\n",
    "        polygon = Polygon(vertices)\n",
    "        return polygon.centroid.y\n",
    "    \n",
    "    # Extract polygons from 'geometry' column\n",
    "    polygons = processv2(df)\n",
    "    \n",
    "    # Add new columns to the DataFrame with polygon metrics\n",
    "    df['Area'] = [calculate_polygon_area(polygon) for polygon in polygons]\n",
    "    df['Perimeter'] = [calculate_polygon_perimeter(polygon) for polygon in polygons]\n",
    "    df['ratio'] = [calculate_height_width_ratio(polygon) for polygon in polygons]\n",
    "    df['x_centroid'] = [calculate_centroid_x(polygon) for polygon in polygons]\n",
    "    df['y_centroid'] = [calculate_centroid_y(polygon) for polygon in polygons]\n",
    "    \n",
    "    # Drop 'geometry' column after extracting needed data\n",
    "    df = df.drop(['geometry'], axis=1)\n",
    "\n",
    "    # Update the first two columns with specified replacements\n",
    "    df.iloc[:, 0] = df.iloc[:, 0].str.replace('N,A', 'NSP_urban')\n",
    "    df.iloc[:, 1] = df.iloc[:, 1].str.replace('N,A', 'NSP_geo')\n",
    "\n",
    "    # Apply one-hot encoding to 'urban_type' and 'geography_type'\n",
    "    one_hot_encoded_urban = df['urban_type'].str.get_dummies(sep=',')\n",
    "    df = df.join(one_hot_encoded_urban)\n",
    "\n",
    "    one_hot_encoded_geo = df['geography_type'].str.get_dummies(sep=',')\n",
    "    df = df.join(one_hot_encoded_geo)\n",
    "\n",
    "    # Drop unneeded columns\n",
    "    df = df.drop(columns=['urban_type', 'geography_type', 'index'])\n",
    "\n",
    "    # Convert date columns to datetime objects\n",
    "    df['date0'] = pd.to_datetime(df['date0'], format='%d-%m-%Y')\n",
    "    df['date1'] = pd.to_datetime(df['date1'], format='%d-%m-%Y')\n",
    "    df['date2'] = pd.to_datetime(df['date2'], format='%d-%m-%Y')\n",
    "    df['date3'] = pd.to_datetime(df['date3'], format='%d-%m-%Y')\n",
    "    df['date4'] = pd.to_datetime(df['date4'], format='%d-%m-%Y')\n",
    "\n",
    "    # Calculate the day differences between date columns\n",
    "    df['Ecart_jours1'] = (df['date1'] - df['date0']).dt.days\n",
    "    df['Ecart_jours2'] = (df['date2'] - df['date1']).dt.days\n",
    "    df['Ecart_jours3'] = (df['date3'] - df['date2']).dt.days\n",
    "    df['Ecart_jours4'] = (df['date4'] - df['date3']).dt.days\n",
    "    \n",
    "    # Drop original date columns after calculating differences\n",
    "    df = df.drop(columns=['date0', 'date1', 'date2', 'date3', 'date4'])\n",
    "\n",
    "    # Apply one-hot encoding to 'change_status_dateX' columns\n",
    "    one_hot_encoded0 = df['change_status_date0'].str.get_dummies(sep=',')\n",
    "    df = df.join(one_hot_encoded0, rsuffix='0')\n",
    "    \n",
    "    one_hot_encoded1 = df['change_status_date1'].str.get_dummies(sep=',')\n",
    "    df = df.join(one_hot_encoded1, rsuffix='1')\n",
    "    \n",
    "    one_hot_encoded2 = df['change_status_date2'].str.get_dummies(sep=',')\n",
    "    df = df.join(one_hot_encoded2, rsuffix='2')\n",
    "\n",
    "    one_hot_encoded3 = df['change_status_date3'].str.get_dummies(sep=',')\n",
    "    df = df.join(one_hot_encoded3, rsuffix='3')\n",
    "\n",
    "    one_hot_encoded4 = df['change_status_date4'].str.get_dummies(sep=',')\n",
    "    df = df.join(one_hot_encoded4, rsuffix='4')\n",
    "    \n",
    "    # Drop the 'change_status_dateX' columns after one-hot encoding\n",
    "    df = df.drop(columns=['change_status_date0', 'change_status_date1', 'change_status_date2', 'change_status_date3', 'change_status_date4'])\n",
    "    \n",
    "    # Colors for further calculations\n",
    "    couleurs = ['red', 'blue', 'green']\n",
    "    \n",
    "    # Dates to consider for calculations\n",
    "    dates = ['date1', 'date2', 'date3', 'date4', 'date5']\n",
    "    \n",
    "    # Loop to calculate mean for each color\n",
    "    for couleur in couleurs:\n",
    "        mean_values = []\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            color_values = []\n",
    "            \n",
    "            for date in dates:\n",
    "                column_name = f'img_{couleur}_mean_{date}'\n",
    "                color_values.append(row[column_name])\n",
    "            \n",
    "            mean_values.append(sum(color_values) / len(color_values))\n",
    "        \n",
    "        df[f'moyenne_{couleur}'] = mean_values\n",
    "    \n",
    "    # Loop to calculate standard deviation for each color\n",
    "    for couleur in couleurs:\n",
    "        std_values = []\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            color_values = []\n",
    "            \n",
    "            for date in dates:\n",
    "                column_name = f'img_{couleur}_std_{date}'\n",
    "                color_values.append(row[column_name])\n",
    "            \n",
    "            std_values.append(sum(color_values) / len(color_values))\n",
    "        \n",
    "        df[f'std_{couleur}'] = std_values\n",
    "    \n",
    "    # Save the processed DataFrame to an Excel file\n",
    "    df.to_excel(output_path, index=False)  # Save without the index\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
