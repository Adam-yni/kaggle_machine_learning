{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "geojson_file = 'train.geojson'\n",
    "gdf = gpd.read_file(geojson_file)\n",
    "\n",
    "\n",
    "\n",
    "xlsx = 'train.xlsx'\n",
    "gdf.to_excel(xlsx, index=False)\n",
    "\n",
    "\n",
    "geojson_file = 'test.geojson'\n",
    "gdf = gpd.read_file(geojson_file)\n",
    "\n",
    "\n",
    "\n",
    "xlsx = 'test.xlsx'\n",
    "gdf.to_excel(xlsx, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import import_ipynb\n",
    "import processing_data\n",
    "import pandas as pd\n",
    "df_test = pd.read_excel('test.xlsx')\n",
    "processing_data.processed_file(df_test,'test_processed')\n",
    "\n",
    "df_train = pd.read_excel('train.xlsx')\n",
    "processing_data.processed_file(df_train,'train_processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From there, I used models that I thought were good based on the f1 score metric I was using and some grid research. Using these models, I predicted the labels I needed, and in the end I came 6th out of over 130 competitors in the kaggle competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using just one classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "X = pd.read_excel('train_processed.xlsx')\n",
    "\n",
    "X_all = X.drop(columns=['change_type'])\n",
    "y_all = X['change_type']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_all_encoded = label_encoder.fit_transform(y_all)\n",
    "\n",
    "dall = xgb.DMatrix(X_all, label=y_all_encoded)\n",
    "\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': len(set(y_all_encoded)),\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.24\n",
    "}\n",
    "\n",
    "num_rounds = 1695\n",
    "bst = xgb.train(params, dall, num_rounds)\n",
    "\n",
    "new_data = pd.read_excel('test_processed.xlsx')\n",
    "\n",
    "X_new = new_data\n",
    "\n",
    "dnew = xgb.DMatrix(X_new)\n",
    "\n",
    "y_pred_encoded = bst.predict(dnew)\n",
    "\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded.astype(int))\n",
    "\n",
    "print(\"Predictions on the new data:\")\n",
    "print(y_pred)\n",
    "\n",
    "correspondance = {\n",
    "    'Demolition': 0,\n",
    "    'Road': 1,\n",
    "    'Residential': 2,\n",
    "    'Commercial': 3,\n",
    "    'Industrial': 4,\n",
    "    'Mega Projects': 5\n",
    "}\n",
    "\n",
    "def mapper(valeur):\n",
    "    return correspondance.get(valeur, valeur)\n",
    "\n",
    "y_pred = np.vectorize(mapper)(y_pred)\n",
    "\n",
    "pred_df = pd.DataFrame(y_pred)\n",
    "pred_df.to_csv(\"sample_submission1.csv\", index=True, index_label='Id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "data = pd.read_excel('train_processed.xlsx')\n",
    "\n",
    "X = data.drop(columns=['change_type'])\n",
    "y = data['change_type']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "model1 = XGBClassifier(max_depth=8, n_estimators=1700, learning_rate=0.25)\n",
    "model2 = XGBClassifier(max_depth=8, n_estimators=1695, learning_rate=0.24)\n",
    "model3 = XGBClassifier(max_depth=8, n_estimators=1705, learning_rate=0.25)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('model1', model1), ('model2', model2), ('model3', model3)], voting='soft')\n",
    "\n",
    "voting_clf.fit(X, y)\n",
    "\n",
    "new_data = pd.read_excel('test_processed.xlsx')\n",
    "\n",
    "X_new = new_data\n",
    "\n",
    "y_pred_encoded = voting_clf.predict(X_new)\n",
    "\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded.astype(int))\n",
    "\n",
    "print(\"Predictions on the new data:\")\n",
    "print(y_pred)\n",
    "\n",
    "correspondance = {\n",
    "    'Demolition': 0,\n",
    "    'Road': 1,\n",
    "    'Residential': 2,\n",
    "    'Commercial': 3,\n",
    "    'Industrial': 4,\n",
    "    'Mega Projects': 5\n",
    "}\n",
    "\n",
    "def mapper(valeur):\n",
    "    return correspondance.get(valeur, valeur)\n",
    "\n",
    "y_pred = np.vectorize(mapper)(y_pred)\n",
    "\n",
    "pred_df = pd.DataFrame(y_pred)\n",
    "pred_df.to_csv(\"sample_submission_voting2.csv\", index=True, index_label='Id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search (after having already narrowed down a few possibilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = pd.read_excel('train_processed.xlsx')\n",
    "\n",
    "X = data.drop(columns=['change_type'])\n",
    "y = data['change_type']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.25, 0.24, 0.26],\n",
    "    'max_depth': [8],\n",
    "    'n_estimators': [1700, 1695],\n",
    "    'gamma': [0],\n",
    "    'alpha': [0],\n",
    "    'lambda': [0]\n",
    "}\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax', num_class=len(set(y)), seed=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=3, scoring='f1_macro')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "best_xgb_classifier = grid_search.best_estimator_\n",
    "y_pred = best_xgb_classifier.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "print(\"Model accuracy with best parameters:\", f1)\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
